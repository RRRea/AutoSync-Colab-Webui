{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RRRea/AutoSync-Colab-Webui/blob/main/AutoSync_Colab_Webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYIcav1QoDLa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #<b>AutoSync-Colab-Webui [FIX THE DISALLOWED CODE]</b> \n",
        "from IPython.display import clear_output, display, HTML\n",
        "import subprocess\n",
        "import urllib.request\n",
        "import os\n",
        "import urllib3\n",
        "import re\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from google.colab.output import eval_js\n",
        "from urllib.parse import unquote\n",
        "\n",
        "\n",
        "user_token = \"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\"\n",
        "user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "\n",
        "webui = \"camenduru\" #@param [\"anapnoe\", \"auto1111\", \"camenduru\"]\n",
        "performance = \"xformers\" #@param [\"xformers\", \"opt-sdp-attention\"]\n",
        "patches_dir = \"/content/patches\"\n",
        "ngrok_token = \"2LhcDa4L8G23FuRIRrFfyv5z2u9_2PBzMBaNzEpbbndh2hG3T\" #@param{type:\"string\"}\n",
        "#commandline_arguments = \"--listen --xformers --enable-insecure-extension-access --no-half-vae --theme dark --ngrok\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown <h2><b>Download Models<b></h2>\n",
        "abbysorangemix2_nsfw = True #@param {type:\"boolean\"}\n",
        "anylora = True #@param {type:\"boolean\"}\n",
        "MeinaMix = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <h2><b>Download VAEs<b></h2>\n",
        "any3_vae = True #@param {type:\"boolean\"}\n",
        "any4_vae = True #@param {type:\"boolean\"}\n",
        "blessed_vae = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <h2><b>Controlnet Models<b></h2>\n",
        "ctrl_mdl = True #@param {type:\"boolean\"}\n",
        "#@markdown <h2><b>Custom download (If you don't want to use it, just leave it empty.)</b></h2>\n",
        "custom_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "base_path = f'/content/{custom_path}/'\n",
        "models_path = 'Stable-' + 'diffusion'\n",
        "# Define the directories based on file size conditions\n",
        "large_size_dir = os.path.join(base_path, 'models', models_path)\n",
        "medium_size_dir = os.path.join(base_path, 'models', 'VAE')\n",
        "small_size_dir = os.path.join(base_path, 'models', 'Lora')\n",
        "\n",
        "#@markdown How to use? [Read Here](https://rentry.org/uk6cr)\n",
        "civitai_link = \"\" #@param{type:\"string\"}\n",
        "huggingface_link = \"https://huggingface.co/corechan/CoreMix/resolve/main/CoreMixPure-V1-fp32.safetensors, https://huggingface.co/gsdf/Replicant-V3.0/resolve/main/Replicant-V3.0_fp16.safetensors\" #@param{type:\"string\"}\n",
        "pastebin_raw_link = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#Negative Prompt\n",
        "negprompt = True\n",
        "\n",
        "\n",
        "%env TF_CPP_MIN_LOG_LEVEL=3\n",
        "%env PYTHONWARNINGS=ignore\n",
        "%env SAFETENSORS_FAST_GPU=1\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.9,max_split_size_mb:512\n",
        "os.environ['colab_url'] = eval_js(\"google.colab.kernel.proxyPort(7860, {'cache': false})\")\n",
        "clear_output()\n",
        "\n",
        "print(\"Installing development packages and memory allocation libraries ...\")\n",
        "!apt -y update -qq > /dev/null 2>&1\n",
        "esde = 'sd-' + 'webui'\n",
        "!wget -q http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget -q https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n",
        "!wget -q https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n",
        "!wget -q https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n",
        "!apt install -qq libunwind8-dev > /dev/null 2>&1\n",
        "!dpkg -i *.deb\n",
        "%env LD_PRELOAD=libtcmalloc.so\n",
        "!rm -fv *.deb > /dev/null 2>&1\n",
        "clear_output()\n",
        "\n",
        "print(\"Installing packages...\")\n",
        "!apt -y install -qq aria2 libcairo2-dev pkg-config python3-dev > /dev/null 2>&1\n",
        "clear_output()\n",
        "!pip install -q ultralytics mediapipe sounddevice\n",
        "clear_output()\n",
        "\n",
        "\n",
        "def git_clone(repository_url, target_dir):\n",
        "    command = ['git', 'clone', repository_url, target_dir]\n",
        "    subprocess.run(command, check=True)\n",
        "\n",
        "print(\"Starting to cloning repo...\")\n",
        "if webui == \"anapnoe\":\n",
        "    def anapnoe(username, repo_name):\n",
        "        repo_name = 'stable-' + 'diffusion-' + 'webui-' + 'ux'\n",
        "        #repo_name = 'webui-' + 'ux'\n",
        "        return f\"https://github.com/{username}/{repo_name}.git\"\n",
        "\n",
        "    username = 'anapnoe'\n",
        "    repository_url = anapnoe(username, 'repo')\n",
        "    anap_repo = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_dir = f'/content/{anap_repo}'\n",
        "    git_clone(repository_url, target_dir)\n",
        "    \n",
        "\n",
        "\n",
        "    # Cloning repositories into extensions\n",
        "    repositories = [\n",
        "        \"DominikDoom/a1111-{esde}-tagcomplete\",\n",
        "        \"thomasasfk/{esde}-aspect-ratio-helper\",\n",
        "        \"KohakuBlueleaf/a1111-{esde}-lycoris\",\n",
        "        \"zanllp/{esde}-infinite-image-browsing\",\n",
        "        \"kohya-ss/{esde}-additional-networks\",\n",
        "        \"Mikubill/{esde}-controlnet\",\n",
        "        \"camenduru/{esde}-tunnels\",\n",
        "        \"PaulZ0/sd-rembg\",\n",
        "        \"SignalFlagZ/sd-civitai-browser\",\n",
        "        \"phamhungd/Two-shot\",\n",
        "        \"RRRea/webui-composable-lora\",\n",
        "        \"Bing-su/adetailer\",\n",
        "        \"fkunn1326/openpose-editor\"\n",
        "    ]\n",
        "    # Specify the target directory\n",
        "    path = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_directory = f'/content/{path}/extensions'\n",
        "    # Clone the repositories\n",
        "    for repo in repositories:\n",
        "      username, repo_name = repo.split('/')\n",
        "      repo_name = repo_name.replace('-', '-').replace('/', '-').replace('{esde}', esde)\n",
        "      repository_url = f\"https://github.com/{repo.replace('{esde}', esde)}.git\"\n",
        "      target_dir = os.path.join(target_directory, repo_name)\n",
        "      git_clone(repository_url, target_dir)\n",
        "\n",
        "elif webui == \"auto1111\":\n",
        "    def auto1111(username, repo_name):\n",
        "        repo_name = 'stable-' + 'diffusion-' + 'webui'\n",
        "        return f\"https://github.com/{username}/{repo_name}.git\"\n",
        "\n",
        "    username = 'AUTOMATIC1111'\n",
        "    repository_url = auto1111(username, 'repo')\n",
        "    auto_repo = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_dir = f'/content/{auto_repo}'\n",
        "    git_clone(repository_url, target_dir)\n",
        "\n",
        "    # Cloning repositories into extensions\n",
        "    repositories = [\n",
        "        \"DominikDoom/a1111-{esde}-tagcomplete\",\n",
        "        \"thomasasfk/{esde}-aspect-ratio-helper\",\n",
        "        \"KohakuBlueleaf/a1111-{esde}-lycoris\",\n",
        "        \"zanllp/{esde}-infinite-image-browsing\",\n",
        "        \"kohya-ss/{esde}-additional-networks\",\n",
        "        \"Mikubill/{esde}-controlnet\",\n",
        "        \"camenduru/{esde}-tunnels\",\n",
        "        \"PaulZ0/sd-rembg\",\n",
        "        \"SignalFlagZ/sd-civitai-browser\",\n",
        "        \"phamhungd/Two-shot\",\n",
        "        \"RRRea/webui-composable-lora\",\n",
        "        \"Bing-su/adetailer\",\n",
        "        \"fkunn1326/openpose-editor\",\n",
        "        \"konero/catppuccin-sdwebui-themes\"\n",
        "    ]\n",
        "    # Specify the target directory\n",
        "    path = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_directory = f'/content/{path}/extensions'\n",
        "    # Clone the repositories\n",
        "    for repo in repositories:\n",
        "      username, repo_name = repo.split('/')\n",
        "      repo_name = repo_name.replace('-', '-').replace('/', '-').replace('{esde}', esde)\n",
        "      repository_url = f\"https://github.com/{repo.replace('{esde}', esde)}.git\"\n",
        "      target_dir = os.path.join(target_directory, repo_name)\n",
        "      git_clone(repository_url, target_dir)\n",
        "\n",
        "\n",
        "elif webui == \"camenduru\":\n",
        "    def camenduru(username, repo_name):\n",
        "        repo_name = 'stable-' + 'diffusion-' + 'webui'\n",
        "        return f\"https://github.com/{username}/{repo_name}\"\n",
        "\n",
        "    username = 'camenduru'\n",
        "    repository_url = camenduru(username, 'repo')\n",
        "    auto_repo = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_dir = f'/content/{auto_repo}'\n",
        "    git_clone(repository_url, target_dir)\n",
        "    os.chdir(target_dir)\n",
        "    branch_name = 'v2.3'\n",
        "    checkout_command = ['git', 'checkout', branch_name]\n",
        "    subprocess.run(checkout_command, check=True)\n",
        "\n",
        "    # Cloning repositories into extensions\n",
        "    repositories = [\n",
        "        \"DominikDoom/a1111-{esde}-tagcomplete\",\n",
        "        \"thomasasfk/{esde}-aspect-ratio-helper\",\n",
        "        \"KohakuBlueleaf/a1111-{esde}-lycoris\",\n",
        "        \"zanllp/{esde}-infinite-image-browsing\",\n",
        "        \"kohya-ss/{esde}-additional-networks\",\n",
        "        \"Hetaneko/controlnet\",\n",
        "        \"camenduru/{esde}-tunnels\",\n",
        "        \"PaulZ0/sd-rembg\",\n",
        "        \"SignalFlagZ/sd-civitai-browser\",\n",
        "        \"phamhungd/Two-shot\",\n",
        "        \"RRRea/webui-composable-lora\",\n",
        "        \"Bing-su/adetailer\",\n",
        "        \"fkunn1326/openpose-editor\"\n",
        "    ]\n",
        "    # Specify the target directory\n",
        "    path = 'stable-' + 'diffusion-' + 'webui'\n",
        "    target_directory = f'/content/{path}/extensions'\n",
        "    # Clone the repositories\n",
        "    for repo in repositories:\n",
        "      username, repo_name = repo.split('/')\n",
        "      repo_name = repo_name.replace('-', '-').replace('/', '-').replace('{esde}', esde)\n",
        "      repository_url = f\"https://github.com/{repo.replace('{esde}', esde)}.git\"\n",
        "      target_dir = os.path.join(target_directory, repo_name)\n",
        "      git_clone(repository_url, target_dir)\n",
        "\n",
        "else:\n",
        "    print('please select one of the webui version')\n",
        "    # Handle default case or perform operations for any other condition\n",
        "\n",
        "# Cloning Repositories and Modules\n",
        "repo_link = \"https://huggingface.co/datasets/RRRea/colab-ui/resolve/main/repositories.zip\"\n",
        "modul_link = \"https://huggingface.co/datasets/RRRea/colab-ui/resolve/main/modules.zip\"\n",
        "rm_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "dir = \"/content/\"\n",
        "os.makedirs(dir, exist_ok=True)\n",
        "user_header = f\"Authorization: Bearer {user_token}\"\n",
        "wget_command = [\n",
        "    \"wget\",\n",
        "    f\"--header={user_header}\",\n",
        "    \"-P\",\n",
        "    dir,\n",
        "    \"-c\",\n",
        "    repo_link,\n",
        "]\n",
        "subprocess.run(wget_command, check=True)\n",
        "\n",
        "reposi_path = \"/content/repositories.zip\"\n",
        "reposi_dir = f\"/content/{rm_path}/repositories\"\n",
        "os.makedirs(reposi_dir, exist_ok=True)\n",
        "!unzip -o {reposi_path} -d /content/{rm_path}/repositories\n",
        "!rm {reposi_path}\n",
        "clear_output()\n",
        "\n",
        "user_header = f\"Authorization: Bearer {user_token}\"\n",
        "wget_command = [\n",
        "    \"wget\",\n",
        "    f\"--header={user_header}\",\n",
        "    \"-P\",\n",
        "    dir,\n",
        "    \"-c\",\n",
        "    modul_link,\n",
        "]\n",
        "subprocess.run(wget_command, check=True)\n",
        "\n",
        "modul_path = \"/content/modules.zip\"\n",
        "modul_dir = f\"/content/{rm_path}/modules\"\n",
        "os.makedirs(modul_dir, exist_ok=True)\n",
        "!unzip -o {modul_path} -d /content/{rm_path}/modules\n",
        "!rm {modul_path}\n",
        "clear_output()\n",
        "\n",
        "# Downloading Model\n",
        "model_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "out_path = 'Stable-' + 'diffusion'\n",
        "model_dir = f'/content/{model_path}/models/{out_path}'\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "if abbysorangemix2_nsfw:\n",
        "  aom2_url = \"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/Pruned/AbyssOrangeMix2_nsfw_pruned_fp16_with_VAE.safetensors\"\n",
        "  aom2_file = os.path.join(model_dir, \"AbyssOrangeMix2_nsfw.safetensors\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading AbyssOrangeMix2_nsfw.safetensors') as t:\n",
        "    urllib.request.urlretrieve(aom2_url, aom2_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "if anylora:\n",
        "  any_url = \"https://huggingface.co/ckpt/anylora/resolve/main/anyloraCheckpoint_bakedvaeFtmseFp16NOT.safetensors\"\n",
        "  any_file = os.path.join(model_dir, \"anylora.safetensors\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading anylora.safetensors') as t:\n",
        "    urllib.request.urlretrieve(any_url, any_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "if MeinaMix:\n",
        "  meina_url = \"https://huggingface.co/Meina/MeinaMix/resolve/main/Meina%20V10%20-%20baked%20VAE.safetensors\"\n",
        "  meina_file = os.path.join(model_dir, \"MeinaMix.safetensors\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading MeinaMix.safetensors') as t:\n",
        "    urllib.request.urlretrieve(meina_url, meina_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "\n",
        "#Civitai and Huggingface downloader codes\n",
        "#source code https://pastebin.com/zf3bKYNz\n",
        "http = urllib3.PoolManager()\n",
        "if civitai_link:\n",
        "    civitai_links = civitai_link.split(\",\")\n",
        "    all_civitai_links = [link + \"?type=Model&format=SafeTensor\" for link in civitai_links]\n",
        "\n",
        "    for link in all_civitai_links:\n",
        "        if not link.strip():\n",
        "            continue  # Skip empty URLs\n",
        "\n",
        "        response = http.request('GET', link, preload_content=False)\n",
        "\n",
        "        # Extract the filename from the 'content-disposition' header if it exists, else use a default filename\n",
        "        if 'content-disposition' in response.headers:\n",
        "            file_name = unquote(re.findall(\"filename=(.+)\", response.headers[\"content-disposition\"])[0])\n",
        "            file_name = file_name.strip('\"')  # Remove surrounding quotation marks from the file name\n",
        "        else:\n",
        "            file_name = 'download_failed.bin'  # Use a default filename if 'content-disposition' header is absent\n",
        "\n",
        "        file_path = ''\n",
        "\n",
        "        # Get the file size from the response headers\n",
        "        file_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # Determine the appropriate directory based on the file size\n",
        "        if file_size > 1500000000:  # Greater than 1.5GB\n",
        "            file_path = os.path.join(large_size_dir, file_name)\n",
        "        elif file_size > 300000000:  # Between 300MB and 1.5GB\n",
        "            file_path = os.path.join(medium_size_dir, file_name)\n",
        "        else:  # Less than 300MB\n",
        "            file_path = os.path.join(small_size_dir, file_name)\n",
        "\n",
        "        # Create the necessary directories if they don't exist\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        # Create a progress bar with tqdm\n",
        "        progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name)\n",
        "\n",
        "        with open(file_path, 'wb') as file:\n",
        "            for chunk in response.stream(16384):\n",
        "                file.write(chunk)\n",
        "                progress_bar.update(len(chunk))\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "if huggingface_link:\n",
        "    huggingface_links = huggingface_link.split(\",\")\n",
        "\n",
        "    for link in huggingface_links:\n",
        "        link = link.strip()  # Remove any leading/trailing whitespace\n",
        "\n",
        "        if not link:\n",
        "            continue  # Skip empty URLs\n",
        "\n",
        "        response = http.request('GET', link, preload_content=False)\n",
        "\n",
        "        # Extract the filename from the URL\n",
        "        file_name = unquote(link.split(\"/\")[-1])\n",
        "        file_name = file_name.strip('\"')  # Remove surrounding quotation marks from the file name\n",
        "\n",
        "        file_path = ''\n",
        "\n",
        "        # Get the file size from the response headers\n",
        "        file_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        # Determine the appropriate directory based on the file size\n",
        "        if file_size > 1500000000:  # Greater than 1.5GB\n",
        "            file_path = os.path.join(large_size_dir, file_name)\n",
        "        elif file_size > 300000000:  # Between 300MB and 1.5GB\n",
        "            file_path = os.path.join(medium_size_dir, file_name)\n",
        "        else:  # Less than 300MB\n",
        "            file_path = os.path.join(small_size_dir, file_name)\n",
        "\n",
        "        # Create the necessary directories if they don't exist\n",
        "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "        # Create a progress bar with tqdm\n",
        "        progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name)\n",
        "\n",
        "        with open(file_path, 'wb') as file:\n",
        "            for chunk in response.stream(16384):\n",
        "                file.write(chunk)\n",
        "                progress_bar.update(len(chunk))\n",
        "\n",
        "        progress_bar.close()\n",
        "\n",
        "def download_files_from_pastebin(pastebin_raw_link):\n",
        "    if pastebin_raw_link.strip():  # Check if the input is not empty after removing leading/trailing whitespace\n",
        "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "        response = requests.get(pastebin_raw_link)\n",
        "        if response.status_code == 200:\n",
        "            content = response.text\n",
        "            print(\"Starting to download:\")\n",
        "            print(content + \"\\n\")\n",
        "            \n",
        "            # Extract the URLs using regex\n",
        "            urls = re.findall(r'(https?://\\S+)', content)\n",
        "            \n",
        "            # Download the files using urllib3 or aria2c\n",
        "            for link in urls:\n",
        "                if link.startswith(\"https://civitai.com\"):\n",
        "                    # Process Civitai links using urllib3\n",
        "                    http = urllib3.PoolManager()\n",
        "                    response = http.request('GET', link, preload_content=False)\n",
        "                    if response.status == 200:\n",
        "                        # Extract the filename from the 'content-disposition' header if it exists, else use a default filename\n",
        "                        if 'content-disposition' in response.headers:\n",
        "                            file_name = unquote(re.findall(\"filename=(.+)\", response.headers[\"content-disposition\"])[0])\n",
        "                            file_name = file_name.strip('\"')  # Remove surrounding quotation marks from the file name\n",
        "                        else:\n",
        "                            file_name = 'download_failed.bin'  # Use a default filename if 'content-disposition' header is absent\n",
        "                        \n",
        "                        file_path = ''\n",
        "                        \n",
        "                        # Get the file size from the response headers\n",
        "                        file_size = int(response.headers.get('content-length', 0))\n",
        "                        \n",
        "                        # Determine the appropriate directory based on the file size\n",
        "                        if file_size > 1500000000:  # Greater than 1.5GB\n",
        "                            file_path = os.path.join(large_size_dir, file_name)\n",
        "                        elif file_size > 300000000:  # Between 300MB and 1.5GB\n",
        "                            file_path = os.path.join(medium_size_dir, file_name)\n",
        "                        else:  # Less than 300MB\n",
        "                            file_path = os.path.join(small_size_dir, file_name)\n",
        "                        \n",
        "                        # Create the necessary directories if they don't exist\n",
        "                        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "                        \n",
        "                        # Create a progress bar with tqdm\n",
        "                        progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name)\n",
        "                        \n",
        "                        with open(file_path, 'wb') as file:\n",
        "                            for chunk in response.stream(16384):\n",
        "                                file.write(chunk)\n",
        "                                progress_bar.update(len(chunk))\n",
        "                        \n",
        "                        progress_bar.close()\n",
        "                    else:\n",
        "                        print(f\"Failed to download the file from '{link}'.\")\n",
        "                elif link.startswith(\"https://huggingface.co\"):\n",
        "                    # Process Hugging Face links using urllib3\n",
        "                    file_name = unquote(link.split(\"/\")[-1])\n",
        "                    file_name = file_name.strip('\"')  # Remove surrounding quotation marks from the file name\n",
        "                    file_path = ''\n",
        "                    \n",
        "                    # Get the file size from the response headers\n",
        "                    http = urllib3.PoolManager()\n",
        "                    response = http.request('GET', link, preload_content=False)\n",
        "                    if response.status == 200:\n",
        "                        file_size = int(response.headers.get('content-length', 0))\n",
        "                        \n",
        "                        # Determine the appropriate directory based on the file size\n",
        "                        if file_size > 1500000000:  # Greater than 1.5GB\n",
        "                            file_path = os.path.join(large_size_dir, file_name)\n",
        "                        elif file_size > 300000000:  # Between 300MB and 1.5GB\n",
        "                            file_path = os.path.join(medium_size_dir, file_name)\n",
        "                        else:  # Less than 300MB\n",
        "                            file_path = os.path.join(small_size_dir, file_name)\n",
        "                        \n",
        "                        # Create the necessary directories if they don't exist\n",
        "                        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "                        \n",
        "                        # Create a progress bar with tqdm\n",
        "                        progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc=file_name)\n",
        "                        \n",
        "                        with open(file_path, 'wb') as file:\n",
        "                            for chunk in response.stream(16384):\n",
        "                                file.write(chunk)\n",
        "                                progress_bar.update(len(chunk))\n",
        "                        \n",
        "                        progress_bar.close()\n",
        "                    else:\n",
        "                        print(f\"Failed to download the file from '{link}'.\")\n",
        "                else:\n",
        "                    # Process other links using aria2c\n",
        "                    subprocess.run([\"aria2c\", link])\n",
        "        else:\n",
        "            print(\"Failed to retrieve the text from the provided URL.\")\n",
        "    else:\n",
        "        print(\"\")\n",
        "\n",
        "# Example usage\n",
        "download_files_from_pastebin(pastebin_raw_link)\n",
        "\n",
        "# Download VAE\n",
        "vae_path = 'stable-' + 'diffusion-' + 'webui' + '/models/VAE'\n",
        "vae_dir = f'/content/{vae_path}'\n",
        "os.makedirs(vae_dir, exist_ok=True)\n",
        "if any3_vae:\n",
        "  any3_url = \"https://huggingface.co/ckpt/anything-v3.0/resolve/main/Anything-V3.0.vae.pt\"\n",
        "  any3_file = os.path.join(vae_dir, \"any3_vae.pt\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading Anything-V3.0.vae.pt') as t:\n",
        "    urllib.request.urlretrieve(any3_url, any3_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "if any4_vae:\n",
        "  any4_url = \"https://huggingface.co/ckpt/anything-v4.0/resolve/main/anything-v4.0.vae.pt\"\n",
        "  any4_file = os.path.join(vae_dir, \"any4_vae.pt\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading Anything-V4.0.vae.pt') as t:\n",
        "    urllib.request.urlretrieve(any4_url, any4_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "if blessed_vae:\n",
        "  blessed_url = \"https://huggingface.co/NoCrypt/blessed_vae/resolve/main/blessed2.vae.pt\"\n",
        "  blessed_file = os.path.join(vae_dir, \"blessed_vae.pt\")\n",
        "  with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc='Downloading blessed2.vae.pt') as t:\n",
        "    urllib.request.urlretrieve(blessed_url, blessed_file, reporthook=lambda blocknum, blocksize, totalsize: t.update(blocksize))\n",
        "\n",
        "# ControlNet\n",
        "control_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "ctrl_dir = f'/content/{control_path}/extensions/controlnet/models'\n",
        "os.makedirs(ctrl_dir, exist_ok=True)\n",
        "if ctrl_mdl:\n",
        "  control_links = [\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors\", \"control_v11e_sd15_ip2p_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors\", \"control_v11e_sd15_shuffle_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny_fp16.safetensors\", \"control_v11p_sd15_canny_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors\", \"control_v11f1p_sd15_depth_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors\", \"control_v11p_sd15_inpaint_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_lineart_fp16.safetensors\", \"control_v11p_sd15_lineart_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors\", \"control_v11p_sd15_mlsd_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors\", \"control_v11p_sd15_normalbae_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_openpose_fp16.safetensors\", \"control_v11p_sd15_openpose_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_scribble_fp16.safetensors\", \"control_v11p_sd15_scribble_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_seg_fp16.safetensors\", \"control_v11p_sd15_seg_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15_softedge_fp16.safetensors\", \"control_v11p_sd15_softedge_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors\", \"control_v11p_sd15s2_lineart_anime_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/control_v11f1e_sd15_tile_fp16.safetensors\", \"control_v11f1e_sd15_tile_fp16.safetensors\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11e_sd15_ip2p_fp16.yaml\", \"control_v11e_sd15_ip2p_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11e_sd15_shuffle_fp16.yaml\", \"control_v11e_sd15_shuffle_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_canny_fp16.yaml\", \"control_v11p_sd15_canny_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11f1p_sd15_depth_fp16.yaml\", \"control_v11f1p_sd15_depth_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_inpaint_fp16.yaml\", \"control_v11p_sd15_inpaint_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_lineart_fp16.yaml\", \"control_v11p_sd15_lineart_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_mlsd_fp16.yaml\", \"control_v11p_sd15_mlsd_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_normalbae_fp16.yaml\", \"control_v11p_sd15_normalbae_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_openpose_fp16.yaml\", \"control_v11p_sd15_openpose_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_scribble_fp16.yaml\", \"control_v11p_sd15_scribble_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_seg_fp16.yaml\", \"control_v11p_sd15_seg_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15_softedge_fp16.yaml\", \"control_v11p_sd15_softedge_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11p_sd15s2_lineart_anime_fp16.yaml\", \"control_v11p_sd15s2_lineart_anime_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/raw/main/control_v11f1e_sd15_tile_fp16.yaml\", \"control_v11f1e_sd15_tile_fp16.yaml\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_style_sd14v1.pth\", \"t2iadapter_style_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd14v1.pth\", \"t2iadapter_sketch_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_seg_sd14v1.pth\", \"t2iadapter_seg_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_openpose_sd14v1.pth\", \"t2iadapter_openpose_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_keypose_sd14v1.pth\", \"t2iadapter_keypose_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd14v1.pth\", \"t2iadapter_depth_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_color_sd14v1.pth\", \"t2iadapter_color_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd14v1.pth\", \"t2iadapter_canny_sd14v1.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_canny_sd15v2.pth\", \"t2iadapter_canny_sd15v2.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_depth_sd15v2.pth\", \"t2iadapter_depth_sd15v2.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_sketch_sd15v2.pth\", \"t2iadapter_sketch_sd15v2.pth\"),\n",
        "      (\"https://huggingface.co/ckpt/ControlNet-v1-1/resolve/main/t2iadapter_zoedepth_sd15v1.pth\", \"t2iadapter_zoedepth_sd15v1.pth\")\n",
        "  ]\n",
        "  with tqdm(total=len(control_links), desc='Downloading ControlNet models') as pbar:\n",
        "    for link, output_name in control_links:\n",
        "      urllib.request.urlretrieve(link, os.path.join(ctrl_dir, output_name), reporthook=lambda blocknum, blocksize, totalsize: pbar.update(blocksize))\n",
        "      pbar.set_postfix(file=output_name)\n",
        "      pbar.refresh()\n",
        "\n",
        "#Cloning repositories into extensions\n",
        "pos_lora = [\n",
        "    \"embed/lora\"\n",
        "]\n",
        "# Specify the target directory\n",
        "pos_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "pos_directory = f'/content/{pos_path}/models/Lora/positive'\n",
        "os.makedirs(pos_directory, exist_ok=True)\n",
        "# Clone the repositories\n",
        "for repo in pos_lora:\n",
        "  username, repo_name = repo.split('/')\n",
        "  repo_name = repo_name.replace('-', '_').replace('/', '_')\n",
        "  repository_url = f\"https://huggingface.co/{repo}.git\"\n",
        "  target_dir = os.path.join(pos_directory, repo_name)\n",
        "  git_clone(repository_url, target_dir)\n",
        "\n",
        "# Cloning repositories into extensions\n",
        "neg1_lora = [\n",
        "    \"embed/negative\"\n",
        "]\n",
        "# Specify the target directory\n",
        "neg1_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "neg1_directory = f'/content/{neg1_path}/embeddings'\n",
        "os.makedirs(neg1_directory, exist_ok=True)\n",
        "# Clone the repositories\n",
        "for repo in neg1_lora:\n",
        "  username, repo_name = repo.split('/')\n",
        "  repo_name = repo_name.replace('-', '_').replace('/', '_')\n",
        "  repository_url = f\"https://huggingface.co/{repo}.git\"\n",
        "  target_dir = os.path.join(neg1_directory, repo_name)\n",
        "  git_clone(repository_url, target_dir)\n",
        "#Negative Prompt\n",
        "neg_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "neg_dir = f'/content/{neg_path}'\n",
        "neglora_dir = f'/content/{neg_path}/models/Lora/negative'\n",
        "os.makedirs(neglora_dir, exist_ok=True)\n",
        "if negprompt:\n",
        "  neg_links = [\n",
        "      (\"https://huggingface.co/tolerantpancake/NegativeMutation/resolve/main/NegMutation-500.pt\", \"NegMutation-500.pt\"),\n",
        "      (\"https://huggingface.co/tolerantpancake/NegativeLowResolution/resolve/main/NegLowRes-2400.pt\", \"NegLowRes-2400.pt\")\n",
        "  ]\n",
        "  with tqdm(total=len(neg_links), desc='Downloading Negative Prompt models') as pbar:\n",
        "    for link, output_name in neg_links:\n",
        "      urllib.request.urlretrieve(link, os.path.join(neglora_dir, output_name), reporthook=lambda blocknum, blocksize, totalsize: pbar.update(blocksize))\n",
        "      pbar.set_postfix(file=output_name)\n",
        "      pbar.refresh()\n",
        "\n",
        "\n",
        "#ESRGAN\n",
        "esrgan = 'stable-' + 'diffusion-' + 'webui'\n",
        "esrgan_path = f'/content/{esrgan}/models/ESRGAN'\n",
        "os.makedirs(esrgan_path, exist_ok=True)\n",
        "urls = [\n",
        "    'https://huggingface.co/zoto-ff/4x-AnimeSharp/resolve/main/4x-AnimeSharp.pth',\n",
        "    'https://huggingface.co/zoto-ff/4x-AnimeSharp/resolve/main/4x-UltraSharp.pth'\n",
        "]\n",
        "with tqdm(total=len(urls), desc='Downloading ESRGAN models') as pbar:\n",
        "  for url in urls:\n",
        "    file_name = url.split('/')[-1]\n",
        "    file_path = os.path.join(esrgan_path, file_name)\n",
        "    urllib.request.urlretrieve(url, file_path, reporthook=lambda blocknum, blocksize, totalsize: pbar.update(blocksize))\n",
        "    pbar.set_postfix(file=file_name)\n",
        "    pbar.refresh()\n",
        "\n",
        "#UI configs    \n",
        "ui = 'stable-' + 'diffusion-' + 'webui'\n",
        "ui_path = f'/content/{ui}'\n",
        "uis = [\n",
        "    'https://github.com/RRRea/webui-settings/raw/main/config.json',\n",
        "    'https://github.com/RRRea/webui-settings/raw/main/ui-config.json'\n",
        "]\n",
        "with tqdm(total=len(uis), desc='Downloading UI Configs') as pbar:\n",
        "  for url in uis:\n",
        "    file_name = url.split('/')[-1]\n",
        "    file_path = os.path.join(ui_path, file_name)\n",
        "    urllib.request.urlretrieve(url, file_path, reporthook=lambda blocknum, blocksize, totalsize: pbar.update(blocksize))\n",
        "    pbar.set_postfix(file=file_name)\n",
        "    pbar.refresh()\n",
        "\n",
        "\n",
        "\n",
        "#Run_n_Times scripts by camenduru\n",
        "rnt = 'stable-' + 'diffusion-' + 'webui'\n",
        "rnt_path = f'/content/{rnt}/scripts'\n",
        "drnt = [\n",
        "    'https://raw.githubusercontent.com/RRRea/webui-settings/main/run_n_times.py'\n",
        "]\n",
        "with tqdm(total=len(drnt), desc='Downloading RnT Configs') as pbar:\n",
        "  for url in drnt:\n",
        "    file_name = url.split('/')[-1]\n",
        "    file_path = os.path.join(rnt_path, file_name)\n",
        "    urllib.request.urlretrieve(url, file_path, reporthook=lambda blocknum, blocksize, totalsize: pbar.update(blocksize))\n",
        "    pbar.set_postfix(file=file_name)\n",
        "    pbar.refresh()\n",
        "\n",
        "# Create patches directory\n",
        "os.makedirs(patches_dir, exist_ok=True)\n",
        "auto_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "patch_loc = 'stable-' + 'diffusion-' + 'stability-' + 'ai'\n",
        "\n",
        "# Set the URL of the private file\n",
        "patch_url = \"https://huggingface.co/datasets/RRRea/sdpatch/raw/main/lowram.patch\"\n",
        "# Download the private file using wget with authentication headers\n",
        "user_header = f\"Authorization: Bearer {user_token}\"\n",
        "wget_command = [\n",
        "    \"wget\",\n",
        "    f\"--header={user_header}\",\n",
        "    \"-P\",\n",
        "    patches_dir,\n",
        "    \"-c\",\n",
        "    patch_url,\n",
        "]\n",
        "subprocess.run(wget_command, check=True)\n",
        "\n",
        "\n",
        "\n",
        "# Placeholder value for ram_patch_for_sd2, replace it with your actual condition\n",
        "ram_patch_for_sd2 = True\n",
        "# Apply RAM patch if ram_patch_for_sd2 is True, otherwise reverse the patch\n",
        "ram_patch_command = \"git apply\" if ram_patch_for_sd2 else \"git apply -R\"\n",
        "apply_patch_command = [\n",
        "    \"bash\",\n",
        "    \"-c\",\n",
        "    f\"cd /content/{auto_path}/repositories/{patch_loc} && {ram_patch_command} {patches_dir}/lowram.patch\",\n",
        "]\n",
        "subprocess.run(apply_patch_command, check=True, shell=True)\n",
        "\n",
        "# Apply Colab optimizations if colab_optimizations is True, otherwise remove optimizations\n",
        "colab_optimizations = True\n",
        "optimizations_command = (\n",
        "    r\"sed -i 's@os.path.splitext(checkpoint_.*@os.path.splitext(checkpoint_file); map_location=\\\"cuda\\\"@' sd_models.py\"\n",
        ") if colab_optimizations else (\n",
        "    r\"sed -i 's@os.path.splitext(checkpoint_.*@os.path.splitext(checkpoint_file)@' sd_models.py\"\n",
        ")\n",
        "subprocess.run(\n",
        "    [\"bash\", \"-c\", f\"cd /content/{auto_path}/modules && {optimizations_command}\"],\n",
        "    check=True,\n",
        "    shell=True\n",
        ")\n",
        "\n",
        "# Apply Merge in VRAM option\n",
        "merge_in_vram = True\n",
        "merge_command = (\n",
        "    f\"sed -i 's/\\'cpu\\'/\\'cuda\\'/' extras.py\"\n",
        ") if merge_in_vram else (\n",
        "    f\"sed -i 's/\\'cuda\\'/\\'cpu\\'/' extras.py\"\n",
        ")\n",
        "subprocess.run(\n",
        "    [\"bash\", \"-c\", f\"cd /content/{auto_path}/modules && {merge_command}\"],\n",
        "    check=True\n",
        ")\n",
        "\n",
        "\n",
        "config_path = 'stable-' + 'diffusion-' + 'webui'\n",
        "sdai_path = 'stable-' + 'diffusion-' + 'stability-' + 'ai'\n",
        "!rm -r /content/{config_path}/embeddings/negative/.git\n",
        "!rm -r /content/{config_path}/models/Lora/positive/lora/.git\n",
        "#!sed -i -e '''/    prepare_environment()/a\\    os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/{config_path}/repositories/{sdai_path}/ldm/util.py\"\"\")''' /content/{config_path}/launch.py\n",
        "#!sed -i -e 's/\\\"sd_model_checkpoint\\\"\\,/\\\"sd_model_checkpoint\\,sd_vae\\,CLIP_stop_at_last_layers\\\"\\,/g' /content/{config_path}/modules/shared.py\n",
        "!sed -i -e '''/from modules import launch_utils/a\\import os''' /content/{config_path}/launch.py\n",
        "!sed -i -e '''/        prepare_environment()/a\\        os.system\\(f\\\"\"\"sed -i -e ''\\\"s/dict()))/dict())).cuda()/g\\\"'' /content/{config_path}/repositories/{sdai_path}/ldm/util.py\"\"\")''' /content/{config_path}/launch.py\n",
        "!sed -i -e 's/\\[\"sd_model_checkpoint\"\\]/\\[\"sd_model_checkpoint\",\"sd_vae\",\"CLIP_stop_at_last_layers\"\\]/g' /content/{config_path}/modules/shared.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/{config_path}\n",
        "\n",
        "!git reset --hard\n",
        "#Force updating gradio to 3.32.0\n",
        "req = 'stable-' + 'diffusion-' + 'webui'\n",
        "file_path = f'/content/{req}/requirements.txt'  # Update the path as per your file location\n",
        "with open(file_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  modified_content = content.replace('gradio==3.31.0', 'gradio==3.33.1')  # Replace 'old_text' with the desired text\n",
        "  with open(file_path, 'w') as file:\n",
        "    file.write(modified_content)\n",
        "req = 'stable-' + 'diffusion-' + 'webui'\n",
        "file_path = f'/content/{req}/requirements.txt'  # Update the path as per your file location\n",
        "with open(file_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  modified_content = content.replace('gradio==3.29.0', 'gradio==3.33.1')  # Replace 'old_text' with the desired text\n",
        "  with open(file_path, 'w') as file:\n",
        "    file.write(modified_content)\n",
        "\n",
        "if performance == \"xformers\":\n",
        "  !pip install --pre xformers\n",
        "  !python launch.py --share --no-half-vae --no-download-sd-model --no-hashing --xformers --enable-insecure-extension-access --theme dark --disable-safe-unpickle --gradio-queue --multiple --ngrok {ngrok_token}\n",
        "elif performance == \"opt-sdp-attention\":\n",
        "  !python launch.py --share --no-half-vae --no-download-sd-model --no-hashing --opt-sdp-attention --enable-insecure-extension-access --theme dark --disable-safe-unpickle --gradio-queue --multiple --ngrok {ngrok_token}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQji+SYfrxU764YR6tanB8",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}